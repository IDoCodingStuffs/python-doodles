{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:40.016812Z",
     "start_time": "2024-06-18T04:46:36.147848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import seaborn as sn\n",
    "\n",
    "from rsna_dataloader import *\n"
   ],
   "id": "86f01bab9611e788",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:40.028423Z",
     "start_time": "2024-06-18T04:46:40.018330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, out_features=512, pretrained_weights=None):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        if pretrained_weights:\n",
    "            self.model.load_state_dict(torch.load(pretrained_weights))\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features=num_ftrs, out_features=out_features)\n",
    "        torch.nn.init.xavier_uniform(self.model.fc.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class FCHead(nn.Module):\n",
    "    def __init__(self, drop_rate=0.1, num_classes=3):\n",
    "        super(FCHead, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            # nn.BatchNorm1d(256),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class CustomLSTM(nn.Module):\n",
    "    hidden_size = 256\n",
    "    num_layers = 3\n",
    "\n",
    "    def __init__(self, num_classes=3, num_levels=5, drop_rate=0.2, resnet_weights=None):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.cnn = CustomResNet(pretrained_weights=resnet_weights)\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=self.hidden_size, dropout=drop_rate, num_layers=self.num_layers,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.heads = [FCHead().to(device) for i in range(num_levels)]\n",
    "\n",
    "    def forward(self, x_3d):\n",
    "        hidden = None\n",
    "\n",
    "        # Iterate over each frame of a video in a video of batch * frames * channels * height * width\n",
    "        for t in range(x_3d.size(1)):\n",
    "            x = self.cnn(x_3d[:, t])\n",
    "            # Pass latent representation of frame through lstm and update hidden state\n",
    "            out, hidden = self.lstm(x.unsqueeze(0), hidden)\n",
    "\n",
    "            # Get the last hidden state (hidden is a tuple with both hidden and cell state in it)\n",
    "\n",
    "        return [head(hidden[0][-1]) for head in self.heads]\n"
   ],
   "id": "87ec21f781d15dfa",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:40.251578Z",
     "start_time": "2024-06-18T04:46:40.029432Z"
    }
   },
   "cell_type": "code",
   "source": "model = torch.load(\"../models/resnet18_lstm_t2stir.pt\")",
   "id": "3b6810f7fbc79359",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:40.257945Z",
     "start_time": "2024-06-18T04:46:40.253584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Lambda(lambda x: (x * 255).astype(np.uint8)),  # Convert back to uint8 for PIL\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "id": "479174f3c0cd8f11",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:41.330574Z",
     "start_time": "2024-06-18T04:46:40.260953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_basepath = \"../data/rsna-2024-lumbar-spine-degenerative-classification/\"\n",
    "training_data = retrieve_training_data(data_basepath)"
   ],
   "id": "cd57daab1829b51f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:41.972610Z",
     "start_time": "2024-06-18T04:46:41.332336Z"
    }
   },
   "cell_type": "code",
   "source": "test_loader = create_series_level_test_datasets_and_loaders(training_data, \"Sagittal T2/STIR\", transform_val, data_basepath + \"train_images\")",
   "id": "b030f04198ee87d5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:41.977644Z",
     "start_time": "2024-06-18T04:46:41.973618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_map = {'normal_mild': 0, 'moderate': 1, 'severe': 2}\n",
    "def get_output_class(val):\n",
    "    if val <= 0.33:\n",
    "        return 0\n",
    "    elif val <= 0.66:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ],
   "id": "84d76fc03da77b18",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:46:42.050863Z",
     "start_time": "2024-06-18T04:46:41.978654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "f8d245a818a4050",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomLSTM(\n",
       "  (cnn): CustomResNet(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (3): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (4): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (5): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (lstm): LSTM(512, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:47:56.683725Z",
     "start_time": "2024-06-18T04:47:17.860252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = []\n",
    "for image, label in tqdm(test_loader):\n",
    "    image = image.to(device)\n",
    "    preds.append((model(image), label))\n",
    "    if len(preds) == 100:\n",
    "        break"
   ],
   "id": "9658c61197216c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 99/1973 [00:38<12:14,  2.55it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T04:49:18.891401Z",
     "start_time": "2024-06-18T04:49:18.034586Z"
    }
   },
   "cell_type": "code",
   "source": "preds",
   "id": "194ae0856d19a0c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([tensor([[ 0.3289, -0.3943, -0.3013]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4153, -0.6202, -0.8320]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4056, -0.3372, -0.2990]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2775, -0.1511, -0.1332]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2998, -0.1235, -0.2097]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3998, -0.3008, -0.2594]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5347, -0.5981, -0.9388]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4067, -0.1408, -0.1969]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2047, -0.0862, -0.1990]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3096, -0.2054, -0.2730]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3819, -0.4629, -0.2406]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3437, -0.5018, -0.6850]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4874, -0.2531, -0.3872]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 2.0028e-01,  1.5936e-04, -1.7605e-01]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3975, -0.2266, -0.3646]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3589, -0.3976, -0.3181]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5264, -0.5939, -0.9047]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4884, -0.3720, -0.3923]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1988, -0.0362, -0.1669]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4990, -0.0725, -0.2978]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3046, -0.2516, -0.2813]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3864, -0.5120, -0.6846]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5064, -0.3213, -0.4143]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2169, -0.0888, -0.0930]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3070, -0.1643, -0.3320]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3089, -0.3844, -0.1897]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3026, -0.3994, -0.5127]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4715, -0.3195, -0.4759]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2120, -0.0307, -0.1677]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2816, -0.1756, -0.4041]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2368, -0.2787, -0.1817]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2848, -0.5156, -0.7263]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5744, -0.2869, -0.4616]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1460, -0.1110, -0.2529]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3928, -0.0485, -0.2204]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3273, -0.3132, -0.2501]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4097, -0.6498, -0.8221]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5079, -0.3827, -0.4042]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2077, -0.0789, -0.2275]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3693, -0.1612, -0.3600]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4483, -0.4394, -0.2231]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5685, -0.5740, -0.8893]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4440, -0.2399, -0.3305]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0998, -0.0903, -0.1148]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4433, -0.0775, -0.3077]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2933, -0.4548, -0.3183]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3060, -0.5631, -0.7996]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5038, -0.2985, -0.3999]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0860, -0.0833, -0.2972]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3181, -0.0582, -0.3248]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3132, -0.2988, -0.2798]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4613, -0.5556, -0.8949]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5251, -0.3069, -0.3524]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1920, -0.1289, -0.2293]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4447, -0.0914, -0.2768]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4642, -0.3778, -0.1733]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4894, -0.6496, -0.6855]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3577, -0.3411, -0.3217]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1734, -0.1161, -0.1741]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3410, -0.1658, -0.2831]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4653, -0.3260, -0.2809]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5327, -0.6889, -0.8457]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5109, -0.3437, -0.3912]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1855, -0.0969, -0.1954]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4620, -0.1127, -0.2548]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3900, -0.3291, -0.1912]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4500, -0.5284, -0.8436]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5592, -0.2558, -0.3444]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1855, -0.1265, -0.2786]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3099, -0.1330, -0.2679]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3699, -0.2084, -0.1067]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3994, -0.4534, -0.7866]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2919, -0.1682, -0.2862]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1708, -0.1126, -0.1712]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1926, -0.0287, -0.2890]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3676, -0.3495, -0.2363]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3614, -0.6071, -0.8111]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5399, -0.3078, -0.3847]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1989, -0.1190, -0.2090]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4552, -0.2494, -0.3811]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4069, -0.3420, -0.3124]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3061, -0.4295, -0.7528]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5495, -0.3617, -0.3520]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1915, -0.0661, -0.1543]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3604, -0.1132, -0.2728]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3125, -0.3050, -0.2564]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3731, -0.5252, -0.6701]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4350, -0.2179, -0.2835]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0964, -0.1024, -0.1966]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4060, -0.1388, -0.4293]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4419, -0.3768, -0.3063]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3870, -0.3719, -0.7782]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5442, -0.2712, -0.3187]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2321, -0.1228, -0.1397]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3182, -0.1889, -0.4629]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3649, -0.4472, -0.2147]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3172, -0.4872, -0.6623]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4862, -0.2101, -0.2991]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2071, -0.0742, -0.2366]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4065, -0.1301, -0.3509]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3688, -0.4298, -0.3170]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4253, -0.4707, -0.6789]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5299, -0.2993, -0.3640]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1816, -0.0929, -0.1918]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2914, -0.1375, -0.2704]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3455, -0.4060, -0.2520]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3624, -0.5622, -0.7895]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5273, -0.3424, -0.3398]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2385, -0.1294, -0.2473]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3693, -0.1627, -0.2533]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4017, -0.3480, -0.2457]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3814, -0.4655, -0.7516]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4307, -0.2466, -0.3343]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1708, -0.0324, -0.2258]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4284, -0.0883, -0.3742]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3667, -0.4730, -0.1131]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4084, -0.4378, -0.8980]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5028, -0.2852, -0.4236]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1576, -0.1151, -0.1417]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3924, -0.0785, -0.2754]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3192, -0.3874, -0.2751]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2064, -0.5112, -0.5565]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4236, -0.2685, -0.2947]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2092, -0.0683, -0.2549]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3538, -0.0951, -0.3682]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.1744, -0.3168, -0.1981]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4189, -0.5428, -0.7846]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5805, -0.2625, -0.3532]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1380, -0.0473, -0.1785]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4351, -0.1993, -0.3647]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3778, -0.4377, -0.2631]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4133, -0.5965, -0.8080]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4803, -0.3483, -0.3565]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1847, -0.0496, -0.1481]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3744, -0.0306, -0.3362]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3428, -0.3726, -0.1859]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3405, -0.6336, -0.8305]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4757, -0.2466, -0.3176]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1412, -0.1362, -0.1888]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2960, -0.1345, -0.2928]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2702, -0.3533, -0.2249]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3721, -0.5836, -0.7067]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5115, -0.3630, -0.4268]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1565, -0.1093, -0.2216]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3918, -0.0991, -0.3559]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2541, -0.3937, -0.2529]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3188, -0.3198, -0.7922]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5104, -0.3357, -0.3302]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1803, -0.0989, -0.1115]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4365, -0.1985, -0.3627]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3073, -0.3443, -0.2360]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4598, -0.6673, -0.9341]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4668, -0.2210, -0.3505]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1976, -0.1002, -0.2541]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3789, -0.1743, -0.2975]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3190, -0.3479, -0.2591]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3738, -0.4727, -0.6847]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5302, -0.3171, -0.3473]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1990, -0.1048, -0.1479]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4772, -0.1615, -0.3024]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3750, -0.4241, -0.2306]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3616, -0.5020, -0.6621]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4786, -0.2795, -0.2691]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2407, -0.1186, -0.1839]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3500, -0.1276, -0.2009]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3413, -0.4078, -0.2765]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4096, -0.4650, -0.7410]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4821, -0.3128, -0.3304]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2194, -0.1107, -0.2066]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3508, -0.1562, -0.4311]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2536, -0.4244, -0.1865]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3999, -0.5784, -0.9038]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4530, -0.3573, -0.3080]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2461, -0.0510, -0.2712]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3746, -0.1785, -0.2663]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3054, -0.4175, -0.1126]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4518, -0.5815, -0.8847]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4828, -0.2723, -0.3803]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2020, -0.0959, -0.2128]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3235, -0.1671, -0.3061]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4693, -0.4187, -0.2433]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2993, -0.5216, -0.7977]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5037, -0.2028, -0.2128]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2000, -0.0374, -0.1454]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3439, -0.0273, -0.2835]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3809, -0.4704, -0.2163]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4392, -0.5846, -0.8430]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5382, -0.2438, -0.3073]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2406, -0.0483, -0.1975]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3712, -0.1268, -0.3321]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3432, -0.3600, -0.2975]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3658, -0.5310, -0.8100]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5599, -0.3094, -0.4096]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1713, -0.1277, -0.1985]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3789, -0.2568, -0.3076]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4167, -0.4792, -0.1968]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3638, -0.5563, -0.6870]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4059, -0.2713, -0.4386]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1193, -0.0309, -0.1438]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3913, -0.1317, -0.3954]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4163, -0.3623, -0.2629]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3601, -0.5618, -0.8299]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4639, -0.2875, -0.2810]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0723, -0.0494, -0.2890]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3510, -0.1355, -0.3218]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3913, -0.4356, -0.2766]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3171, -0.5545, -0.6300]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5036, -0.2851, -0.3707]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2103, -0.0842, -0.2197]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3300, -0.0112, -0.4053]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4249, -0.4470, -0.2833]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4451, -0.5315, -0.8098]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4466, -0.2547, -0.2582]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2607, -0.0559, -0.2345]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4225, -0.1676, -0.3459]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3912, -0.4292, -0.2094]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4258, -0.5133, -0.8219]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3332, -0.1229, -0.2532]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1685, -0.0336, -0.1377]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4350, -0.0269, -0.3186]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4332, -0.3651, -0.2137]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3969, -0.5332, -0.9749]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5528, -0.3749, -0.3737]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2142, -0.1104, -0.2711]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3574, -0.2505, -0.3147]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4589, -0.4495, -0.2607]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4900, -0.5568, -0.8798]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5349, -0.2798, -0.3469]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2337, -0.0935, -0.1845]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3880, -0.1774, -0.4289]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3679, -0.2843, -0.2487]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4220, -0.6619, -0.8520]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5413, -0.3108, -0.3550]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2045, -0.0447, -0.2503]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3333, -0.0893, -0.3156]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2783, -0.3918, -0.2328]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3840, -0.4652, -0.7623]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4970, -0.3227, -0.3361]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2167, -0.0617, -0.1668]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2901, -0.0787, -0.4125]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3509, -0.3662, -0.2006]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2798, -0.5233, -0.7240]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3763, -0.2009, -0.1622]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1691, -0.0517, -0.1762]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2991, -0.2096, -0.4276]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3736, -0.3759, -0.2586]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3686, -0.5268, -0.7705]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5185, -0.2813, -0.2688]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2044, -0.0549, -0.2122]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2981, -0.1334, -0.2415]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3853, -0.3210, -0.2838]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4982, -0.6119, -0.7744]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4399, -0.2285, -0.3779]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1863,  0.0037, -0.1259]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2826, -0.1827, -0.3580]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2557, -0.2441, -0.2609]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4492, -0.4525, -0.8101]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5386, -0.2196, -0.3222]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1801, -0.1001, -0.2806]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3099, -0.1414, -0.3062]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3446, -0.4213, -0.2904]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3414, -0.4156, -0.7913]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4605, -0.3729, -0.3713]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1789, -0.1812, -0.2361]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3113, -0.2276, -0.2887]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3811, -0.3377, -0.2680]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4758, -0.4892, -0.7633]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4058, -0.2871, -0.2050]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1783, -0.0716, -0.1080]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3659, -0.1408, -0.3263]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4991, -0.4139, -0.1205]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3456, -0.4887, -0.6981]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3884, -0.1977, -0.3586]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1919, -0.1243, -0.2318]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3462, -0.1619, -0.2630]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4289, -0.2615, -0.2492]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3928, -0.6396, -0.8195]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4172, -0.2537, -0.2326]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1995, -0.0072, -0.2308]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4267, -0.1271, -0.3349]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4105, -0.3996, -0.2708]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4321, -0.5334, -0.8631]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3949, -0.3247, -0.2542]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2468, -0.0351, -0.1820]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3384, -0.1260, -0.2680]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3495, -0.4480, -0.2337]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5337, -0.6590, -0.9340]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4717, -0.3249, -0.3353]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1547, -0.1251, -0.2739]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2820, -0.1723, -0.3149]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3718, -0.3207, -0.2438]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3216, -0.5376, -0.7950]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4698, -0.2898, -0.3170]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1049, -0.0395, -0.1821]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3177, -0.0746, -0.2681]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2925, -0.3056, -0.1390]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3764, -0.5083, -0.8591]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4832, -0.2470, -0.2641]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2725, -0.1209, -0.2124]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3621, -0.0859, -0.3088]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4125, -0.3287, -0.2317]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3648, -0.5214, -0.7642]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4046, -0.3464, -0.4079]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1194, -0.1209, -0.1545]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3747, -0.1256, -0.3578]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2880, -0.4020, -0.3299]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2771, -0.4128, -0.8109]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4244, -0.2622, -0.3745]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2066, -0.1260, -0.2089]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4345, -0.1984, -0.3208]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4224, -0.4180, -0.2883]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4926, -0.5958, -0.9730]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4765, -0.3322, -0.3560]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2094, -0.0832, -0.2363]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3434, -0.1291, -0.2263]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2111, -0.3860, -0.2055]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3736, -0.5343, -0.6624]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5495, -0.2943, -0.3311]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1799, -0.0381, -0.2302]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4018, -0.2021, -0.2923]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4200, -0.5174, -0.2149]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4201, -0.3836, -0.5372]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4773, -0.2877, -0.3767]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1470, -0.0880, -0.2109]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2882, -0.2013, -0.3821]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3945, -0.3599, -0.2030]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4616, -0.6430, -0.6939]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3428, -0.2178, -0.4622]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1785, -0.1051, -0.2486]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4203, -0.1296, -0.3834]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4168, -0.2662, -0.2301]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2836, -0.4846, -0.7492]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4769, -0.2418, -0.1298]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1334, -0.0595, -0.1140]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3759, -0.1795, -0.3344]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3745, -0.3819, -0.2736]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3980, -0.3741, -0.5694]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5418, -0.3088, -0.4101]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1882, -0.1200, -0.2642]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4377, -0.1600, -0.2489]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4215, -0.4223, -0.2664]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4710, -0.5819, -0.8450]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4872, -0.1498, -0.4039]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2306, -0.0864, -0.1297]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2556, -0.1233, -0.2535]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3384, -0.3500, -0.1584]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5261, -0.6039, -0.9429]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5008, -0.1870, -0.2533]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1813, -0.0117, -0.1896]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3998, -0.1342, -0.2988]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3377, -0.4212, -0.2582]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5047, -0.5242, -0.9922]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5866, -0.2252, -0.4423]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1781, -0.1341, -0.1995]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3548, -0.2021, -0.4123]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4808, -0.3166, -0.1669]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4500, -0.5333, -0.8068]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5515, -0.3549, -0.3879]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1381,  0.0032, -0.1874]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3838, -0.1871, -0.2892]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2902, -0.4250, -0.1101]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3058, -0.5344, -0.7215]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5218, -0.2577, -0.3304]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2256, -0.0801, -0.2040]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3918, -0.1213, -0.1853]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3511, -0.3749, -0.2939]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4145, -0.5983, -1.0178]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5635, -0.3743, -0.3901]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1898, -0.1088, -0.2397]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3409, -0.2321, -0.3462]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4030, -0.3980, -0.2890]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4338, -0.6633, -0.8106]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4118, -0.2631, -0.2795]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2083, -0.0404, -0.2686]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4440, -0.1425, -0.3748]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3018, -0.3887, -0.3198]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3634, -0.5839, -0.8339]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5587, -0.2979, -0.2995]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2386, -0.0308, -0.1695]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4006, -0.1475, -0.2491]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4145, -0.4338, -0.2492]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3905, -0.6189, -0.9176]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4150, -0.2927, -0.3512]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1395, -0.0799, -0.1270]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3259, -0.2394, -0.3179]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4019, -0.3318, -0.1549]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4117, -0.6077, -0.8495]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3952, -0.2709, -0.2587]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2252, -0.0849, -0.3035]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4192, -0.0441, -0.3107]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2809, -0.4074, -0.3421]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3213, -0.4646, -0.6671]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5885, -0.2592, -0.3077]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1368, -0.0769, -0.2257]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2807, -0.2198, -0.2380]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3415, -0.2912, -0.1789]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3354, -0.5518, -0.7890]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5391, -0.1921, -0.2697]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1582, -0.0552, -0.2604]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3043, -0.2188, -0.2526]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3444, -0.3936, -0.2613]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3150, -0.5575, -0.6104]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5495, -0.3167, -0.3946]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1740, -0.0915, -0.1897]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2932, -0.2628, -0.3024]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4448, -0.3987, -0.2558]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2426, -0.3926, -0.6080]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4216, -0.2390, -0.2894]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2030, -0.0713, -0.1339]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2607, -0.3183, -0.1686]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4202, -0.3368, -0.2478]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4140, -0.6218, -0.8045]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4556, -0.2021, -0.3041]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1452, -0.0509, -0.0879]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3796, -0.2020, -0.3434]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3434, -0.4203, -0.2035]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4107, -0.5456, -0.7496]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4804, -0.3595, -0.3358]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0831, -0.0262, -0.2084]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3827, -0.0689, -0.3433]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4103, -0.3482, -0.2545]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3175, -0.3420, -0.5849]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4799, -0.2899, -0.3221]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1808, -0.1187, -0.1069]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3491, -0.1140, -0.3045]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2954, -0.3604, -0.1825]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4675, -0.5212, -0.8299]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5337, -0.2672, -0.5013]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1777, -0.0868, -0.1859]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3695, -0.0716, -0.2259]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3731, -0.3531, -0.3297]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4095, -0.6626, -0.7522]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5237, -0.2775, -0.3439]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1780, -0.0023, -0.0758]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3265, -0.1690, -0.3056]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3894, -0.3320, -0.3383]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2824, -0.4175, -0.7455]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4770, -0.3445, -0.3392]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1845, -0.1335, -0.2208]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2666, -0.0071, -0.4566]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[0, 0, 1],\n",
       "           [0, 0, 1],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3086, -0.3995, -0.3201]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3024, -0.3851, -0.6881]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5163, -0.3185, -0.2628]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2320, -0.0314, -0.1379]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4517, -0.1767, -0.3668]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2999, -0.4094, -0.2154]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3403, -0.6427, -0.7921]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4586, -0.0594, -0.4402]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.0779, -0.0760, -0.1415]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2952, -0.1451, -0.2210]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4748, -0.4040, -0.2323]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4564, -0.5233, -0.7648]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5477, -0.2841, -0.2643]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1677, -0.0671, -0.1690]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2545, -0.1515, -0.2937]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.2966, -0.4047, -0.2804]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2017, -0.7137, -0.6077]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5199, -0.3010, -0.2335]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2248, -0.0847, -0.1191]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3575, -0.1067, -0.2263]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [0, 1, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3683, -0.3069, -0.2649]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3690, -0.5158, -0.7974]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5639, -0.3084, -0.2770]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2111, -0.0495, -0.1988]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2005, -0.0378, -0.4031]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4571, -0.3842, -0.2272]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4513, -0.4541, -0.9654]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4378, -0.3236, -0.3617]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2383, -0.0772, -0.1812]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3978, -0.1684, -0.3562]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 0, 1],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3523, -0.4531, -0.2513]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4024, -0.4756, -0.7406]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5192, -0.3506, -0.2778]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2279, -0.1093, -0.0947]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3348, -0.1773, -0.2774]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3812, -0.3494, -0.1157]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4052, -0.4884, -0.8480]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5049, -0.3870, -0.3812]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1238, -0.0451, -0.1924]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4236, -0.0707, -0.3313]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.4477, -0.2945, -0.2738]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1820, -0.3741, -0.6523]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5112, -0.2816, -0.3227]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2381, -0.1095, -0.1919]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4466, -0.1509, -0.2800]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3661, -0.3806, -0.2623]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3863, -0.5844, -0.9074]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5184, -0.2695, -0.4152]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1809, -0.0959, -0.1702]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3974, -0.1608, -0.4137]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [0, 1, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3133, -0.2420, -0.1437]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4136, -0.5177, -0.7061]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.4449, -0.2391, -0.2561]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.2171, -0.0685, -0.1174]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3300, -0.1777, -0.2686]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32)),\n",
       " ([tensor([[ 0.3587, -0.2841, -0.1090]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3096, -0.6000, -0.7745]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.5169, -0.2030, -0.2792]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.1875, -0.1440, -0.1399]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>),\n",
       "   tensor([[ 0.3914, -0.1321, -0.3596]], device='cuda:0',\n",
       "          grad_fn=<AddmmBackward0>)],\n",
       "  tensor([[[1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0],\n",
       "           [1, 0, 0]]], dtype=torch.int32))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def scores_to_classes(arr):\n",
    "    ret = []\n",
    "    for i in range(0, len(arr)-1, 2):\n",
    "        if arr[i] == 0:\n",
    "            ret.append(0)\n",
    "        elif arr[i] == 1:\n",
    "            ret.append(2)\n",
    "        else:\n",
    "            ret.append(1)\n",
    "            \n",
    "    return ret"
   ],
   "id": "c3b284d1e9e1d0a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pred_classes = [(scores_to_classes(e[0][0]), scores_to_classes(e[1][0])) for e in preds]",
   "id": "40bc07ba792bc59b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pred_classes_0 = [e[0][4] for e in pred_classes]\n",
    "pred_classes_0_ = [e[1][4] for e in pred_classes]"
   ],
   "id": "306d3f738316bf58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cf_matrix = confusion_matrix(pred_classes_0, pred_classes_0_)\n",
    "df_cm = pd.DataFrame(cf_matrix)\n",
    "plt.figure(figsize=(12, 7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()\n"
   ],
   "id": "ecd41874315f7e19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training_data",
   "id": "a1b3650bfe7fca9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "training_data[training_data[\"condition\"] == \"Spinal Canal Stenosis\"].groupby([\"severity\"]).count()",
   "id": "862cd2422c3412e5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
