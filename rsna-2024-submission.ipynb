{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-06T04:59:33.755943Z",
     "start_time": "2024-06-06T04:59:33.090822Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class ConvToFC(nn.Module):\n",
    "    def __init__(self, in_channels, in_dims, out_dims):\n",
    "        super(ConvToFC, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, 1, kernel_size=(in_dims, 1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc = nn.Linear(in_dims, out_dims)\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.relu(self.conv(x)))\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        #self.outc = (OutConv(64, n_classes))\n",
    "        self.outc = (ConvToFC(64, in_dims=512, out_dims=n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self):\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time_ns\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:02:29.024021Z",
     "start_time": "2024-06-06T05:02:28.006710Z"
    }
   },
   "id": "864c4fd02c824c3c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, labels, images, transform=None, target_transform=None):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:02:36.502627Z",
     "start_time": "2024-06-06T05:02:36.496874Z"
    }
   },
   "id": "2689b15dadf02d92"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_location = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\"\n",
    "\n",
    "def load_dataset():\n",
    "    # Load data, create dataset\n",
    "    train_data = pd.read_csv(f'{data_location}/train.csv')\n",
    "\n",
    "    train_images = os.listdir(f'{data_location}//train_images')\n",
    "    train_images = list(filter(lambda x: x.find('.DS') == -1, train_images))\n",
    "    train_images = [(x, f'{data_location}//train_images/{x}') for x in\n",
    "                    train_images]\n",
    "\n",
    "    image_metadata_set = {p[0]: {'folder_path': p[1],\n",
    "                             'SeriesInstanceUIDs': []\n",
    "                             }\n",
    "                      for p in train_images}\n",
    "\n",
    "    for m in image_metadata_set:\n",
    "        image_metadata_set[m]['SeriesInstanceUIDs'] = list(\n",
    "            filter(lambda x: x.find('.DS') == -1,\n",
    "                   os.listdir(image_metadata_set[m]['folder_path'])\n",
    "                   )\n",
    "        )\n",
    "\n",
    "    df_meta_f = pd.read_csv(f'{data_location}//train_series_descriptions.csv')\n",
    "\n",
    "    for k in tqdm(image_metadata_set):\n",
    "        for s in image_metadata_set[k]['SeriesInstanceUIDs']:\n",
    "            if 'SeriesDescriptions' not in image_metadata_set[k]:\n",
    "                image_metadata_set[k]['SeriesDescriptions'] = []\n",
    "            try:\n",
    "                image_metadata_set[k]['SeriesDescriptions'].append(\n",
    "                    df_meta_f[(df_meta_f['study_id'] == int(k)) &\n",
    "                              (df_meta_f['series_id'] == int(s))]['series_description'].iloc[0])\n",
    "            except:\n",
    "                print(\"Failed on\", s, k)\n",
    "\n",
    "    return train_data, image_metadata_set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:04:09.837383Z",
     "start_time": "2024-06-06T05:04:09.824848Z"
    }
   },
   "id": "c78ad367a447a27d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_imageset_for_patient(sample_patient, train_data, image_metadata_set):\n",
    "    # !TODO: Index by some patient id\n",
    "    ptobj = image_metadata_set[str(sample_patient['study_id'])]\n",
    "\n",
    "    im_list_dcm = {}\n",
    "    for idx, i in enumerate(ptobj['SeriesInstanceUIDs']):\n",
    "        im_list_dcm[i] = {'images': [], 'description': ptobj['SeriesDescriptions'][idx]}\n",
    "        images = glob.glob(f\"{ptobj['folder_path']}/{ptobj['SeriesInstanceUIDs'][idx]}/*.dcm\")\n",
    "        for j in sorted(images, key=lambda x: int(x.split('/')[-1].replace('.dcm', ''))):\n",
    "            im_list_dcm[i]['images'].append({\n",
    "                'SOPInstanceUID': j.split('/')[-1].replace('.dcm', ''),\n",
    "                'dicom': pydicom.dcmread(j)})\n",
    "\n",
    "    return {e['description']: [x['dicom'].pixel_array for x in e['images']] for e in im_list_dcm.values()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:04:39.668645Z",
     "start_time": "2024-06-06T05:04:39.653044Z"
    }
   },
   "id": "30276cb5a83872a3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "LABELS = ['Normal/Mild', 'Moderate', 'Severe']\n",
    "EXCLUDE_COLS = [\"study_id\"]\n",
    "def convert_to_output_vector(train_data: pd.DataFrame):\n",
    "    # !TODO: Naive approach\n",
    "    # !TODO: Submission requires bin probabilities, rather than 1d score, need to think about that\n",
    "    train_data_features = train_data[[e for e in train_data.columns if e not in EXCLUDE_COLS]]\n",
    "    train_data_features = [[LABELS.index(e_) for e_ in e] for e in train_data_features.values]\n",
    "    return train_data_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:04:58.515969Z",
     "start_time": "2024-06-06T05:04:58.501036Z"
    }
   },
   "id": "cf6e0e74e462690a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train() -> UNet:\n",
    "    EPOCH_COUNT = 50\n",
    "\n",
    "    study_data, image_metadata_set = load_dataset()\n",
    "    study_data = study_data.dropna()\n",
    "    # First approach: just get each individual image, tack on expected labels 0-2, train away\n",
    "    study_data[\"features\"] = convert_to_output_vector(study_data)\n",
    "    study_data = study_data[[\"study_id\", \"features\"]]\n",
    "\n",
    "    # !TODO: Split within same study?\n",
    "    # !TODO: Tripartite split vs bipartite?\n",
    "    train_data, val_data = train_test_split(study_data, test_size=0.2)\n",
    "\n",
    "    num_classes = len(study_data[\"features\"].iloc[0])\n",
    "    model = UNet(n_channels=1, n_classes=num_classes)\n",
    "\n",
    "    exp = []\n",
    "    train_set = []\n",
    "\n",
    "    for i in range(10):\n",
    "        image_examples = get_imageset_for_patient(train_data.iloc[i], train_data, image_metadata_set)\n",
    "        train_set += [np.array(e, dtype=np.int32) for e in image_examples[\"Sagittal T1\"]]\n",
    "        exp += [train_data[\"features\"].iloc[i] for e in image_examples[\"Sagittal T1\"]]\n",
    "\n",
    "    # !TODO: Loader args?\n",
    "    train_dataset = CustomImageDataset(exp, train_set)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True)\n",
    "    #pred = model(list(train_loader)[0].float().unsqueeze(0))\n",
    "\n",
    "    # Just the first one that comes to mind. To be tooned\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_fn = nn.L1Loss()\n",
    "\n",
    "    for epoch in range(EPOCH_COUNT):\n",
    "        total_loss = 0\n",
    "        start = time_ns()\n",
    "        for image, target in train_loader:\n",
    "            # !TODO: Admit any image size\n",
    "            if image.shape != (1, 512, 512):\n",
    "                continue\n",
    "            optimizer.zero_grad()\n",
    "            output = model(image.float().unsqueeze(0))\n",
    "            loss = loss_fn(output.squeeze(0).squeeze(0), torch.tensor(target).unsqueeze(0))\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        end = time_ns()\n",
    "        print(\"Loss at epoch\", epoch, total_loss)\n",
    "        print(\"Seconds elapsed at epoch\", epoch, (end - start) // 1e9)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-06T05:05:16.932906Z",
     "start_time": "2024-06-06T05:05:16.930970Z"
    }
   },
   "id": "67c2d7ba6001c14a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "912171899dda8dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5fb48ddc79a1fa41"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
